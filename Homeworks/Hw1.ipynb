{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hw1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canaytsr/GlobalAIHubMLCourse/blob/main/Homeworks/Hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJTh32Qvougc"
      },
      "source": [
        "# **1) How would you define Machine Learning?**\r\n",
        "\r\n",
        "Machine learning is an artificial intelligence subset that can learn and make inferences from the given (entered) data, such as face recognition, document classification, spam detection, and thus improve the performance of existing systems.\r\n",
        "\r\n",
        "# **2) What are the differences between Supervised and Unsupervised Learning? Specify example 3 algorithms for each of these.**\r\n",
        "\r\n",
        "* Supervised learning model will use the training data to learn a link between the input and the outputs. Unsupervised learning does not use output data. \r\n",
        "\r\n",
        "* Supervised learning model produces an accurate result. Unsupervised learning model may give less accurate result as compared to supervised learning.\r\n",
        "\r\n",
        "* Supervised learning model takes direct feedback to check if it is predicting correct output or not but Unsupervised learning model does not take any feedback.\r\n",
        "\r\n",
        "* Unsupervised learning does not need any supervision to train the model however Supervised learning needs supervision to train the model.\r\n",
        "\r\n",
        "* Supervised learning can be categorized in Classification and Regression problems. Unsupervised Learning can be classified in Clustering and Associations problems.\r\n",
        "\r\n",
        "\r\n",
        "**Supervised Learning Algorithms:** Linear Regression, Logistic Regression, \r\n",
        "Multi-class Classification\r\n",
        "\r\n",
        "**Unsupervised Learning Algorithms:** Cluster Algorithms, K-means, Hierarchical Clustering\r\n",
        "\r\n",
        "# **3) What are the test and validation set, and why would you want to use them?**\r\n",
        "\r\n",
        "The test set is a set of data that is used to test the model after the model has already been trained.\r\n",
        "The test set is  used only to assess the performance (i.e. generalization) of a fully specified classifier.\r\n",
        "\r\n",
        "The validation set is a set of data, separate from the training set, that is used to validate our model during training.\r\n",
        "We use the validation set  for evaluate the performance of own model for different combinations of hyperparameter values.\r\n",
        "(we set the values for the hyperparameters)\r\n",
        "\r\n",
        "# **4) What are the main preprocessing steps? Explain them in detail. Why we need to prepare our data?**\r\n",
        "**1.Acquire the dataset**\r\n",
        "\r\n",
        "To build and develop Machine Learning models, we must first acquire the relevant dataset.\r\n",
        "\r\n",
        "**2.Import all the crucial libraries**\r\n",
        "\r\n",
        "Since Python is the most extensively used and also the most preferred library by Data Scientists around the world, how we import Python libraries for data preprocessing in Machine Learning.\r\n",
        "\r\n",
        "**Machine Learning are:**\r\n",
        "\r\n",
        "**NumPy :** NumPy is the fundamental package for scientific calculation in Python. Hence, it is used for inserting any type of mathematical operation in the code. Using NumPy, we can also add large multidimensional arrays and matrices in your code. \r\n",
        "\r\n",
        "**Pandas :** Pandas is an excellent open-source Python library for data manipulation and analysis. It is extensively used for importing and managing the datasets. It packs in high-performance, easy-to-use data structures and data analysis tools for Python.\r\n",
        "\r\n",
        "**Matplotlib :** Matplotlib is a Python 2D plotting library that is used to plot any type of charts in Python. It can deliver publication-quality figures in numerous hard copy formats and interactive environments across platforms (IPython shells, Jupyter notebook, web application servers,etc.)\r\n",
        "\r\n",
        "**3. Import the dataset**\r\n",
        "\r\n",
        "In this step, we need to import the dataset/s that we have gathered for the ML project at hand. \r\n",
        "\r\n",
        "**4. Identifying and handling the missing values**\r\n",
        "\r\n",
        "In data preprocessing, it is pivotal to identify and correctly handle the missing values, failing we don't do this, we might draw inaccurate and faulty conclusions and inferences from the data.\r\n",
        "\r\n",
        "**Basically, there are two ways to handle missing data:**\r\n",
        "\r\n",
        "**Deleting a particular row:** In this method, we remove a specific row that has a null value for a feature or a particular column where more than 75% of the values are missing. However, this method is not 100% efficient, and  we use it only when the dataset has adequate samples. \r\n",
        "\r\n",
        "**Calculating the mean:** This method is useful for features having numeric data like age, salary, year, etc. This method can add variance to the dataset, and any loss of data can be efficiently negated. Hence, it yields better results compared to the first method (omission of rows/columns). Another way of approximation is through the deviation of neighbouring values. However, this works best for linear data.\r\n",
        "\r\n",
        "**5. Encoding the categorical data**\r\n",
        "\r\n",
        "Categorical data refers to the information that has specific categories within the dataset.\r\n",
        "\r\n",
        "**6. Splitting the dataset**\r\n",
        "\r\n",
        "Every dataset for Machine Learning model must be split into two separate sets â€“ training set and test set.\r\n",
        "Training set denotes the subset of a dataset that is used for training the machine learning model. Test set, is the subset of the dataset that is used for testing the machine learning model. The ML model uses the test set to predict outcomes.The validation set is used to evaluate a given model, but this is for frequent evaluation. \r\n",
        "\r\n",
        "**7. Feature scaling**\r\n",
        "\r\n",
        "Feature scaling marks the end of the data preprocessing in Machine Learning. It is a method to standardize the independent variables of a dataset within a specific range. In other words, feature scaling limits the range of variables so that you can compare them on common grounds.\r\n",
        "\r\n",
        "# **5) How you can explore countionus and discrete variables?**\r\n",
        "**A discrete variable** is characterized by gaps or interruptions in the values that it can assume.(Discrete Variables are used for Classification.)\r\n",
        "\r\n",
        "**A continuous variable** can assume any value within a specified relevant interval of values assumed by the variable.(Continuous Variables are used for Regression.)\r\n",
        "\r\n",
        "# **6) Analyse the plot given below. (What is the plot and variable type, check the distribution and make comment about how you can preproccess it.)**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JENBfN8mX43"
      },
      "source": [
        "This histogram graph have continuous variable so this one number does not represent the data well.This plot immediately affords a few insights about the variable. In this data set normalization the distribution can used bimodal distribution. For normalize the datas we can eliminate outliers.\r\n",
        "\r\n"
      ]
    }
  ]
}